{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:56:29.578561Z","iopub.execute_input":"2025-05-04T15:56:29.578799Z","iopub.status.idle":"2025-05-04T15:56:31.660238Z","shell.execute_reply.started":"2025-05-04T15:56:29.578775Z","shell.execute_reply":"2025-05-04T15:56:31.659602Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"conll2003\")\nprint(dataset[\"train\"][0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:56:31.661526Z","iopub.execute_input":"2025-05-04T15:56:31.661875Z","iopub.status.idle":"2025-05-04T15:56:43.218318Z","shell.execute_reply.started":"2025-05-04T15:56:31.661857Z","shell.execute_reply":"2025-05-04T15:56:43.217702Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/12.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"675fcf01955d4bba93a6baa3013f6ff2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"conll2003.py:   0%|          | 0.00/9.57k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a6764e28a3e4d889004db1b495b1ae2"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for conll2003 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/conll2003.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/983k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6a2d3a6fd3345788514c9e747005c0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/14041 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b720052b386c435c8db7fa008e1dff70"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/3250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c799eb9974d04a1792d01758d9116be6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/3453 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b56bfd4e186d44228a01c18100a8f450"}},"metadata":{}},{"name":"stdout","text":"{'id': '0', 'tokens': ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7], 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0], 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from transformers import AutoTokenizer\nfrom datasets import DatasetDict\nimport numpy as np\n\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n\ndef tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(\n        examples[\"tokens\"], \n        truncation=True, \n        is_split_into_words=True,\n        padding=\"max_length\",  # Добавляем padding для единообразия\n        max_length=128         # Указываем максимальную длину\n    )\n    \n    labels = []\n    for i, label in enumerate(examples[\"ner_tags\"]):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n        previous_word_idx = None\n        label_ids = []\n        \n        for word_idx in word_ids:\n            # Специальные токены получают метку -100\n            if word_idx is None:\n                label_ids.append(-100)\n            # Для новых слов используем соответствующую метку\n            elif word_idx != previous_word_idx:\n                label_ids.append(label[word_idx])\n            # Для подслов используем -100\n            else:\n                label_ids.append(-100)\n            previous_word_idx = word_idx\n            \n        labels.append(label_ids)\n    \n    tokenized_inputs[\"labels\"] = labels\n    return tokenized_inputs\n\n# Применяем функцию к датасету\ntokenized_datasets = dataset.map(\n    tokenize_and_align_labels,\n    batched=True,\n    batch_size=32,  # Размер батча для обработки\n    remove_columns=dataset[\"train\"].column_names  # Удаляем исходные колонки\n)\n\n# Устанавливаем формат для PyTorch\ntokenized_datasets.set_format(\"torch\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:56:43.219117Z","iopub.execute_input":"2025-05-04T15:56:43.219355Z","iopub.status.idle":"2025-05-04T15:56:56.341208Z","shell.execute_reply.started":"2025-05-04T15:56:43.219337Z","shell.execute_reply":"2025-05-04T15:56:56.340455Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9156cf4163ca46f3b722679fcee6480f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de4ef4ecde92404fb2eafa28f28a7c7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f9e2cbf688a422c980ef4b0222cc433"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ef0e05039dd45ef8b096b629e045d85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/14041 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e8858379b7746a5952c2824002f6cfe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b06bd62ab3ba4d68b90977febe727ff9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3453 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6db71ab1f612443f8a82dcc4e319f557"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\nlabel_list = dataset[\"train\"].features[\"ner_tags\"].feature.names\n# Загрузка модели\nmodel = AutoModelForTokenClassification.from_pretrained(\n    \"bert-base-cased\", \n    num_labels=len(label_list),\n    ignore_mismatched_sizes=True  # Игнорировать несоответствие размеров\n)\n\n# Исправленные аргументы обучения\nargs = TrainingArguments(\n    output_dir=\"./ner_model\",\n    eval_strategy=\"epoch\",  # Изменено с evaluation_strategy на eval_strategy\n    learning_rate=2e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=1,\n    weight_decay=0.01,\n    save_strategy=\"no\",\n    logging_dir='./logs',  # Добавляем директорию для логов\n    report_to=\"none\"       # Отключаем отчеты если не используете WandB\n)\n\n# Создаем Trainer\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=tokenized_datasets[\"train\"].select(range(2000)),\n    eval_dataset=tokenized_datasets[\"validation\"].select(range(500)),\n)\n\n# Запускаем обучение\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:58:20.240307Z","iopub.execute_input":"2025-05-04T15:58:20.241059Z","iopub.status.idle":"2025-05-04T15:59:00.110127Z","shell.execute_reply.started":"2025-05-04T15:58:20.241035Z","shell.execute_reply":"2025-05-04T15:59:00.109454Z"}},"outputs":[{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"184aab472a90479daceced894821fdc5"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:34, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.263046</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=125, training_loss=0.4760972900390625, metrics={'train_runtime': 36.6674, 'train_samples_per_second': 54.544, 'train_steps_per_second': 3.409, 'total_flos': 130656646656000.0, 'train_loss': 0.4760972900390625, 'epoch': 1.0})"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"metrics = trainer.evaluate()\nprint(metrics)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:59:18.320973Z","iopub.execute_input":"2025-05-04T15:59:18.321490Z","iopub.status.idle":"2025-05-04T15:59:20.926421Z","shell.execute_reply.started":"2025-05-04T15:59:18.321465Z","shell.execute_reply":"2025-05-04T15:59:20.925800Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [32/32 00:02]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.26304590702056885, 'eval_runtime': 2.5956, 'eval_samples_per_second': 192.633, 'eval_steps_per_second': 12.329, 'epoch': 1.0}\n","output_type":"stream"}],"execution_count":6}]}